#Setup: Importing the modules and setting the random variables. 
import numpy as np
np.random.seed(42)
import tensorflow as tf
tf.random.set_random_seed(42)
from keras.models import Sequential, load_model
from keras.layers import Activation, Dense
from keras.layers import LSTM, Dropout
from keras.layers import TimeDistributed
from keras.layers.core import Dense, Activation, Dropout, RepeatVector
from keras.optimizers import RMSprop
import matplotlib.pyplot as plt
import pickle
import sys
import heapq
import seaborn as sns
from pylab import rcParams
%matplotlib inline
sns.set(style='whitegrid', palette='muted', font_scale=1.5)
rcParams['figure.figsize'] = 12, 5

#Loading The dataset
path = 'HindiBible.txt'
text = open(path).read().lower()
print("length is: " , len(text))
# Expected output if using the same dataset :
#length is:  3693012

#Preprocessing the data
chars = sorted(list(set(text)))
char_indices = dict((c, i) for i, c in enumerate(chars))
indices_char = dict((i, c) for i, c in enumerate(chars))
print(f'unique chars: {len(chars)}')
### Expected output
unique chars: 19 ###

#The corpus is cut into chunks of 40 characters and then is separated by 3 blank spaces between them
SEQUENCE_LENGTH = 40
step = 3
sentences = []
next_chars = []
for i in range(0, len(text) - SEQUENCE_LENGTH, step):
    sentences.append(text[i: i + SEQUENCE_LENGTH])
    next_chars.append(text[i + SEQUENCE_LENGTH])
print(f'num training examples: {len(sentences)}')
 
#Creating one-hot encoding vector
X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)
for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        X[i, t, char_indices[char]] = 1
    y[i, char_indices[next_chars[i]]] = 1

#Building the model
#Single LSTM layer with 128 neurons and softmax layer with 57 neurons for output
model = Sequential()
model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))
model.add(Dense(len(chars)))
model.add(Activation('softmax'))

#Training
optimizer = RMSprop(lr=0.01)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history

#Saving the model
model.save('keras_model.h5')
pickle.dump(history, open("history.p", "wb"))
model = load_model('keras_model.h5')
history = pickle.load(open("history.p", "rb"))

#Evaluation
plt.plot(history['accuracy'])
plt.plot(history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left');

plt.plot(history['loss'])
plt.plot(history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left');

#Testing the model
def prepare_input(text):
    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))
    for t, char in enumerate(text):
        x[0, t, char_indices[char]] = 1.
        
    return x
    
def sample(preds, top_n=3):
    preds = np.asarray(preds).astype('float64')
    preds = np.log(preds)
    exp_preds = np.exp(preds)
    preds = exp_preds / np.sum(exp_preds)
    
    return heapq.nlargest(top_n, range(len(preds)), preds.take)

def predict_completion(text):
    original_text = text
    generated = text
    completion = ''
    while True:
        x = prepare_input(text)
        preds = model.predict(x, verbose=0)[0]
        next_index = sample(preds, top_n=1)[0]
        next_char = indices_char[next_index]
        text = text[1:] + next_char
        completion += next_char
        
        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':
            return completion
            
def predict_completions(text, n=3):
    x = prepare_input(text)
    preds = model.predict(x, verbose=0)[0]
    next_indices = sample(preds, n)
    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]
    
#Making a sequence of 40 characters 
quotes = ["तब यहोवा ने कैन से कहा, तू क्यों क्रोधित हुआ?",
          "जिस से जहाज ऊपर को उठने लगा, और वह पृथ्वी पर से ऊंचा उठ गया।और जल बढ़ते बढ़ते पृथ्वी पर बहुत ही बढ़ गया,",
          " उन सब जीवित प्राणियों की भी सृष्टि की जो चलते फिरते हैं जिन से जल बहुत ही भर गया और एक एक जाति के उड़ने वाले पक्षियों की भी सृष्टि की: और परमेश्वर ने देखा कि अच्छा है"]

for q in quotes:
    seq = q[:40].lower()
    print(seq)
    print(predict_completions(seq, 5))
    print()













